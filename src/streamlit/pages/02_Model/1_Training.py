import sys
import time
from pathlib import Path

import numpy as np
import pandas as pd

import streamlit as st

# Ajouter le rÃ©pertoire racine au path pour les imports
sys.path.append(str(Path(__file__).parent.parent))  # Ajouter le dossier streamlit

# Calcul correct du project_root
current_file = Path(__file__)  # pages/02_Model/1_Training.py
current_dir = current_file.parent  # pages/02_Model/
streamlit_dir = current_dir.parent.parent  # streamlit/
src_dir = streamlit_dir.parent  # src/
project_root = src_dir.parent  # DS_COVID/

sys.path.append(str(project_root))

try:
    from src.features.Pipelines.Pipeline_Sklearn import PipelineManager
except ImportError:
    st.error("âŒ Impossible d'importer PipelineManager. VÃ©rifiez le chemin d'accÃ¨s.")

st.title("ğŸ‹ï¸ EntraÃ®nement du ModÃ¨le")

st.markdown(
    """
Cette page permet d'entraÃ®ner diffÃ©rents modÃ¨les de classification pour la dÃ©tection COVID-19 
en utilisant des pipelines sklearn configurables.
"""
)

# Sidebar pour les paramÃ¨tres
with st.sidebar:
    st.header("âš™ï¸ Configuration")

    # SÃ©lection du type de donnÃ©es
    data_source = st.selectbox(
        "Source des donnÃ©es",
        ["DonnÃ©es simulÃ©es (test)", "Dataset COVID-19", "Upload personnalisÃ©"],
    )

    # ParamÃ¨tres gÃ©nÃ©raux
    test_size = st.slider("Taille du jeu de test (%)", 10, 50, 20) / 100
    random_state = st.number_input("Seed alÃ©atoire", 1, 9999, 42)

# Interface principale
tab1, tab2, tab3 = st.tabs(["ï¿½ Configuration", "ğŸš€ EntraÃ®nement", "ğŸ“Š RÃ©sultats"])

with tab1:
    st.header("Configuration des Pipelines")

    # Charger le gestionnaire de pipelines
    try:
        # Construire le chemin vers le fichier de configuration
        config_path = (
            project_root
            / "src"
            / "features"
            / "Pipelines"
            / "Pipeline_Sklearn_config.json"
        )

        if not config_path.exists():
            st.error(f"âŒ Fichier de configuration non trouvÃ©: {config_path}")
            st.info(
                "ğŸ”§ VÃ©rifiez que le fichier Pipeline_Sklearn_config.json existe dans src/features/Pipelines/"
            )
            manager = None
        else:
            manager = PipelineManager(str(config_path))

        if manager is None:
            st.error("âŒ Impossible de charger le gestionnaire de pipelines")
            selected_configs = []
            configs = []
        else:
            # Afficher les configurations disponibles
            st.subheader("ğŸ“‹ Pipelines Disponibles")
            configs = manager.get_available_configs()

            config_df = pd.DataFrame(configs)
            st.dataframe(config_df, use_container_width=True)

            # SÃ©lection des pipelines Ã  entraÃ®ner
            st.subheader("ğŸ¯ SÃ©lection des Pipelines")
            selected_configs = st.multiselect(
                "Choisissez les pipelines Ã  entraÃ®ner:",
                options=[config["name"] for config in configs],
                default=["basic_rf", "fast_prototype"] if configs else [],
                help="SÃ©lectionnez un ou plusieurs pipelines pour comparaison",
            )

        if selected_configs and configs:
            st.success(f"âœ… {len(selected_configs)} pipeline(s) sÃ©lectionnÃ©(s)")

            # Afficher les dÃ©tails des pipelines sÃ©lectionnÃ©s
            with st.expander("ğŸ” DÃ©tails des pipelines sÃ©lectionnÃ©s"):
                for config_name in selected_configs:
                    config_details = next(
                        (c for c in configs if c["name"] == config_name), None
                    )
                    if config_details:
                        st.write(f"**{config_name}**: {config_details['description']}")
                        st.write(
                            f"- GridSearch: {'âœ…' if config_details['grid_search'] else 'âŒ'}"
                        )
                        st.write(f"- CV Folds: {config_details['cv_folds']}")
        elif selected_configs and not configs:
            st.warning("âš ï¸ Pipelines sÃ©lectionnÃ©s mais configuration non chargÃ©e")

    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement de la configuration: {e}")
        selected_configs = []

with tab2:
    st.header("EntraÃ®nement des ModÃ¨les")

    if not selected_configs:
        st.warning(
            "âš ï¸ Veuillez sÃ©lectionner au moins un pipeline dans l'onglet Configuration"
        )
    else:
        # ParamÃ¨tres d'entraÃ®nement
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“Š DonnÃ©es")
            if data_source == "DonnÃ©es simulÃ©es (test)":
                n_samples = st.slider("Nombre d'Ã©chantillons", 100, 5000, 1000)
                n_features = st.selectbox(
                    "Taille des features", [1024, 4096, 16384], index=2
                )
                n_classes = st.selectbox("Nombre de classes", [2, 4], index=1)

        with col2:
            st.subheader("ğŸ›ï¸ ParamÃ¨tres")
            enable_comparison = st.checkbox("Activer la comparaison", True)
            save_results = st.checkbox("Sauvegarder les rÃ©sultats", True)

        # Bouton d'entraÃ®nement
        if st.button("ğŸš€ Lancer l'EntraÃ®nement", type="primary"):
            # GÃ©nÃ©rer les donnÃ©es selon la source
            if data_source == "DonnÃ©es simulÃ©es (test)":
                with st.spinner("ğŸ”„ GÃ©nÃ©ration des donnÃ©es simulÃ©es..."):
                    np.random.seed(random_state)
                    X = np.random.rand(n_samples, n_features)
                    y = np.random.randint(0, n_classes, n_samples)

                    # Division train/test
                    split_idx = int((1 - test_size) * n_samples)
                    X_train, X_test = X[:split_idx], X[split_idx:]
                    y_train, y_test = y[:split_idx], y[split_idx:]

                    st.success(
                        f"âœ… DonnÃ©es gÃ©nÃ©rÃ©es: {X_train.shape[0]} train, {X_test.shape[0]} test"
                    )

                # EntraÃ®nement des pipelines
                results_container = st.container()
                progress_bar = st.progress(0)
                status_text = st.empty()

                results = {}

                for i, config_name in enumerate(selected_configs):
                    status_text.text(f"ğŸ‹ï¸ EntraÃ®nement de {config_name}...")
                    progress_bar.progress((i) / len(selected_configs))

                    # Container pour les rÃ©sultats de ce pipeline
                    with results_container:
                        with st.expander(
                            f"ğŸ“ˆ RÃ©sultats - {config_name}", expanded=True
                        ):
                            result_placeholder = st.empty()

                            try:
                                # Capture des logs avec redirection
                                start_time = time.time()

                                # EntraÃ®nement
                                result = manager.train_pipeline(
                                    config_name, X_train, y_train, X_test, y_test
                                )

                                end_time = time.time()
                                training_duration = end_time - start_time

                                results[config_name] = result

                                # Affichage des rÃ©sultats
                                col1, col2, col3 = st.columns(3)

                                with col1:
                                    st.metric(
                                        "PrÃ©cision Test",
                                        f"{result.get('test_accuracy', 0):.3f}",
                                        delta=None,
                                    )

                                with col2:
                                    st.metric(
                                        "F1-Score",
                                        f"{result.get('test_f1', 0):.3f}",
                                        delta=None,
                                    )

                                with col3:
                                    st.metric(
                                        "Score CV",
                                        f"{result.get('cv_mean', 0):.3f}",
                                        delta=f"Â±{result.get('cv_std', 0):.3f}",
                                    )

                                # DÃ©tails supplÃ©mentaires
                                if "best_params" in result:
                                    st.write("ğŸ”§ **Meilleurs paramÃ¨tres:**")
                                    st.json(result["best_params"])

                                st.success(
                                    f"âœ… {config_name} terminÃ© en {training_duration:.1f}s"
                                )

                            except Exception as e:
                                st.error(f"âŒ Erreur avec {config_name}: {str(e)}")

                # Finalisation
                progress_bar.progress(1.0)
                status_text.text("âœ… EntraÃ®nement terminÃ©!")

                # Sauvegarde des rÃ©sultats dans la session
                st.session_state["training_results"] = results
                st.session_state["comparison_data"] = {
                    "configs": selected_configs,
                    "data_info": {
                        "n_samples": n_samples,
                        "n_features": n_features,
                        "n_classes": n_classes,
                        "test_size": test_size,
                    },
                }

            else:
                st.info("ğŸš§ Chargement de donnÃ©es rÃ©elles non encore implÃ©mentÃ©")

with tab3:
    st.header("Comparaison des RÃ©sultats")

    if "training_results" in st.session_state:
        results = st.session_state["training_results"]

        if results:
            # Tableau de comparaison
            st.subheader("ğŸ“Š Tableau Comparatif")

            comparison_data = []
            for config_name, result in results.items():
                row = {
                    "Pipeline": config_name,
                    "PrÃ©cision Test": f"{result.get('test_accuracy', 0):.4f}",
                    "F1-Score": f"{result.get('test_f1', 0):.4f}",
                    "Score CV": f"{result.get('cv_mean', 0):.4f}",
                    "Ã‰cart-type CV": f"{result.get('cv_std', 0):.4f}",
                    "Temps (s)": f"{result['training_time'].total_seconds():.1f}",
                }

                if "best_score" in result:
                    row["Meilleur GridSearch"] = f"{result['best_score']:.4f}"

                comparison_data.append(row)

            df_comparison = pd.DataFrame(comparison_data)
            st.dataframe(df_comparison, use_container_width=True)

            # Meilleur modÃ¨le
            best_model = max(
                results.items(), key=lambda x: x[1].get("test_accuracy", 0)
            )
            st.success(
                f"ğŸ† **Meilleur modÃ¨le**: {best_model[0]} avec une prÃ©cision de {best_model[1].get('test_accuracy', 0):.4f}"
            )

            # Graphiques de comparaison
            st.subheader("ğŸ“ˆ Visualisations")

            col1, col2 = st.columns(2)

            with col1:
                # Graphique en barres des prÃ©cisions
                metrics_df = pd.DataFrame(
                    {
                        "Pipeline": [r["Pipeline"] for r in comparison_data],
                        "PrÃ©cision": [
                            float(r["PrÃ©cision Test"]) for r in comparison_data
                        ],
                    }
                )
                st.bar_chart(metrics_df.set_index("Pipeline"))

            with col2:
                # Temps d'entraÃ®nement
                time_df = pd.DataFrame(
                    {
                        "Pipeline": [r["Pipeline"] for r in comparison_data],
                        "Temps": [float(r["Temps (s)"]) for r in comparison_data],
                    }
                )
                st.bar_chart(time_df.set_index("Pipeline"))

            # Bouton de tÃ©lÃ©chargement des rÃ©sultats
            csv_data = df_comparison.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger les rÃ©sultats (CSV)",
                data=csv_data,
                file_name=f"covid_pipeline_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )
    else:
        st.info(
            "â„¹ï¸ Aucun rÃ©sultat d'entraÃ®nement disponible. Lancez d'abord un entraÃ®nement dans l'onglet prÃ©cÃ©dent."
        )
