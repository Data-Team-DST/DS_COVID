"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¯ CELLULE DE CONFIGURATION STANDALONE - COPIER-COLLER DANS VOS NOTEBOOKS â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INSTRUCTIONS:
-------------
1. Copiez TOUT le contenu de cette cellule
2. Collez-le comme PREMIÃˆRE CELLULE de votre notebook
3. ExÃ©cutez la cellule
4. Les variables sont prÃªtes Ã  l'emploi !

Cette cellule est 100% autonome et fonctionne partout :
âœ… Google Colab (clone + installe automatiquement)
âœ… WSL / Linux Local
âœ… Tout environnement Jupyter

APRÃˆS EXÃ‰CUTION, VOUS POUVEZ UTILISER:
- config: Objet de configuration (config.batch_size, config.data_dir, etc.)
- ENV: Environnement dÃ©tectÃ© ('colab', 'wsl', 'local')
- Tous les imports des transformers

"""

# =============================================================================
# IMPORTS STANDARDS
# =============================================================================

import os
import sys
import subprocess
from pathlib import Path


# =============================================================================
# DÃ‰TECTION AUTOMATIQUE DE L'ENVIRONNEMENT
# =============================================================================

def detect_environment():
    """DÃ©tecte l'environnement (colab, wsl, local)"""
    try:
        import google.colab
        return "colab"
    except ImportError:
        is_wsl = os.path.exists('/proc/version') and 'microsoft' in open('/proc/version').read().lower()
        return "wsl" if is_wsl else "local"

ENV = detect_environment()
print(f"ğŸŒ Environnement: {ENV.upper()}")


# =============================================================================
# BOOTSTRAP COLAB (Clone + Install si nÃ©cessaire)
# =============================================================================

if ENV == "colab":
    print("\nğŸš€ Bootstrap Colab...")
    
    os.chdir('/content')
    if not os.path.exists('/content/Data_Pipeline'):
        print("ğŸ“¥ Clonage du repository...")
        subprocess.run(['git', 'clone', 'https://github.com/L-Poca/Data_Pipeline.git'], check=True)
    
    os.chdir('/content/Data_Pipeline')
    
    # Checkout de la branche rafael_cleaning
    result = subprocess.run(
        ['git', 'checkout', '-b', 'rafael_cleaning', 'origin/rafael_cleaning'],
        capture_output=True,
        text=True
    )
    if result.returncode != 0:
        # Si la branche locale existe dÃ©jÃ , juste switcher
        subprocess.run(['git', 'checkout', 'rafael_cleaning'], capture_output=True)
    
    # âœ… setup.py dÃ©tecte automatiquement Colab et n'installe AUCUNE dÃ©pendance
    # Les packages natifs Colab sont utilisÃ©s (NumPy 2.0.2, TensorFlow 2.19.0, etc.)
    print("âœ… Utilisation des packages Colab natifs:")
    print("   â€¢ NumPy 2.0.2")
    print("   â€¢ TensorFlow 2.19.0")
    print("   â€¢ SciPy 1.16.3")
    print("   â€¢ scikit-learn 1.6.1")
    
    # Installation du package en mode Ã©ditable (sans dÃ©pendances - dÃ©tection Colab dans setup.py)
    print("ğŸ“¦ Installation du package...")
    result = subprocess.run(['pip', 'install', '-e', '.', '--quiet'], capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âš ï¸ Erreur installation: {result.stderr}")
    else:
        print("âœ… Package installÃ©")
    
    print("ğŸ’¾ Montage Google Drive...")
    from google.colab import drive
    drive.mount('/content/drive')
    
    # Extraction dataset
    for archive in ['/content/drive/MyDrive/DS_COVID/archive_covid.zip']:
        if os.path.exists(archive):
            print("ğŸ“¦ Extraction dataset...")
            os.makedirs('./data/raw/', exist_ok=True)
            subprocess.run(['unzip', '-o', '-q', archive, '-d', './data/raw/COVID-19_Radiography_Dataset/'])
            break
    
    print("âœ… Bootstrap terminÃ©")


# =============================================================================
# CONFIGURATION DES CHEMINS
# =============================================================================

# DÃ©terminer project_root selon l'environnement
if ENV == "colab":
    project_root = Path('/content/Data_Pipeline')
elif ENV == "wsl":
    project_root = Path('/home/cepa/DST/projet_DS/Data_Pipeline/Data_Pipeline')
else:  # local
    # Depuis un notebook dans src/notebooks/
    project_root = Path.cwd().parent.parent

# Ajouter src/ au sys.path pour les imports
# src_path = str(project_root / 'src')
# if src_path not in sys.path:
#     sys.path.insert(0, src_path)
#     print(f"âœ… Chemin src/ ajoutÃ©: {src_path}")

# Charger la configuration depuis JSON
from src.utils.config import build_config

config = build_config(project_root, ENV)

# Exports pour compatibilitÃ© avec anciens notebooks
data_dir = config.data_dir
categories = config.classes
img_size = config.img_size


# =============================================================================
# IMPORTS DES TRANSFORMERS
# =============================================================================

try:
    from src.features.Pipelines.Transformateurs.image_loaders import ImageLoader
    from src.features.Pipelines.Transformateurs.image_preprocessing import (
        ImageResizer, ImageNormalizer, ImageFlattener
    )
    from src.features.Pipelines.Transformateurs.image_augmentation import (
        ImageAugmenter, ImageRandomCropper
    )
    from src.features.Pipelines.Transformateurs.image_features import (
        ImageHistogram, ImagePCA, ImageStandardScaler
    )
    print("âœ… Transformers importÃ©s")
except ImportError as e:
    print(f"âš ï¸ Erreur import transformers: {e}")


# =============================================================================
# IMPORTS ML/DL
# =============================================================================

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras

# =============================================================================
# CONFIGURATION MATPLOTLIB
# =============================================================================

plt.rcParams['figure.figsize'] = (15, 10)
sns.set_style('whitegrid')

# =============================================================================
# AFFICHAGE DU RÃ‰SUMÃ‰
# =============================================================================

print("\n" + "=" * 70)
print("âœ… CONFIGURATION PRÃŠTE - Data Pipeline")
print("=" * 70)
print(f"ğŸ“‚ Projet: {project_root}")
print(f"ğŸ“Š Dataset: {data_dir}")
print(f"ğŸ·ï¸ Classes: {', '.join(categories)}")
print(f"ğŸ›ï¸ Images: {img_size}")
print(f"ğŸ”§ Batch: {config.batch_size} | Ã‰poques: {config.epochs}")
print(f"ğŸ“ Dataset accessible: {'âœ…' if data_dir.exists() else 'âŒ'}")
if not data_dir.exists():
    print(f"   âš ï¸ CrÃ©ez le dossier ou placez les donnÃ©es dans: {data_dir}")
print("=" * 70)
print("\nğŸ’¡ Variables disponibles:")
print("   â€¢ config: Configuration complÃ¨te (Config object)")
print("   â€¢ project_root: Racine du projet (Path)")
print("   â€¢ data_dir: Dossier des donnÃ©es (Path)")
print("   â€¢ categories: Liste des 4 classes")
print("   â€¢ img_size: Taille des images (tuple)")
print("   â€¢ ENV: Environnement actuel")
print("\nğŸ¯ Transformers disponibles:")
print("   â€¢ ImageLoader, ImageResizer, ImageNormalizer, ImageFlattener")
print("   â€¢ ImageAugmenter, ImageRandomCropper")
print("   â€¢ ImageHistogram, ImagePCA, ImageStandardScaler")
print("=" * 70)
